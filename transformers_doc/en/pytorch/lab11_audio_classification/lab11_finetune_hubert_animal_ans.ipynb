{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 11 Audio Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "from datasets import load_dataset, Audio,DatasetDict\n",
    "from transformers import HubertForSequenceClassification, Wav2Vec2FeatureExtractor, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Wellyowo/esc50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset)\n",
    "print(dataset['train'][0][\"audio\"].keys())\n",
    "print(dataset['train'][0][\"audio\"][\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the feature extractor\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/hubert-base-ls960\")\n",
    "\n",
    "# Set the sampling rate to match the feature extractor\n",
    "sampling_rate = feature_extractor.sampling_rate\n",
    "\n",
    "# Cast the audio column to the correct sampling rate\n",
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=sampling_rate))\n",
    "\n",
    "# Create a mapping from category names to numerical IDs\n",
    "categories = dataset['train']['category']\n",
    "category_to_id = {category: idx for idx, category in enumerate(np.unique(categories))}\n",
    "num_categories = len(category_to_id)\n",
    "\n",
    "# Function to preprocess the audio data\n",
    "def prepare_dataset(example):\n",
    "    audio = example[\"audio\"]\n",
    "\n",
    "    inputs = feature_extractor(\n",
    "        audio[\"array\"],\n",
    "        sampling_rate=audio[\"sampling_rate\"],\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True\n",
    "    )\n",
    "\n",
    "    example[\"input_values\"] = inputs.input_values[0]  # Extract the tensor from the batch\n",
    "    example[\"input_length\"] = len(audio[\"array\"]) / audio[\"sampling_rate\"]\n",
    "    example[\"labels\"] = category_to_id[example[\"category\"]]\n",
    "    return example\n",
    "\n",
    "# Preprocess the dataset\n",
    "dataset = dataset.map(prepare_dataset, remove_columns=[\"filename\", \"target\", \"esc10\", \"take\", \"src_file\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Wellyowo/hubert-esc50-finetuned-v2\"\n",
    "model_id = \"facebook/hubert-base-ls960\"\n",
    "model = HubertForSequenceClassification.from_pretrained(model_id, num_labels=num_categories)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "\toutput_dir=f\"{model_name}-results\",\n",
    "\tevaluation_strategy=\"epoch\",\n",
    "\tsave_strategy=\"epoch\",\n",
    "\tlearning_rate=5e-5,\n",
    "\tper_device_train_batch_size=8,\n",
    "\tnum_train_epochs=10,\n",
    "\tlogging_dir='./logs',\n",
    "\tlogging_steps=10,\n",
    "\tpush_to_hub=False,\n",
    "\thub_model_id=model_name,\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\tpredictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "\treturn {\"accuracy\": accuracy_score(eval_pred.label_ids, predictions)}\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "\tmodel=model,\n",
    "\targs=training_args,\n",
    "\ttrain_dataset=dataset[\"train\"],\n",
    "\teval_dataset=dataset[\"test\"],\n",
    "\ttokenizer=feature_extractor,\n",
    "\tcompute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "kwargs = {\n",
    "\t\"finetuned_from\": model_id,\n",
    "\t\"tasks\": \"audio-classification\",\n",
    "\t\"dataset\": \"ESC-50\",\n",
    "\t\"tags\": [\"audio-classification\", \"hubert\", \"esc50\"]\n",
    "}\n",
    "\n",
    "# trainer.push_to_hub(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test your model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install ipython\n",
    "from IPython.display import Audio, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned model\n",
    "model_name = \"Wellyowo/hubert-esc50-finetuned\"\n",
    "model = HubertForSequenceClassification.from_pretrained(model_name)\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_audio(input):\n",
    "\taudio_array = input[\"audio\"][\"array\"]\n",
    "\tsampling_rate = input[\"audio\"][\"sampling_rate\"]\n",
    "\tdisplay(Audio(audio_array, rate=sampling_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor\n",
    "\n",
    "\n",
    "def predict_and_audio(inputs):\n",
    "    with torch.no_grad():\n",
    "        input_values = feature_extractor(inputs[\"audio\"][\"array\"], return_tensors=\"pt\", sampling_rate=16000).input_values\n",
    "\n",
    "        logits = model(input_values).logits\n",
    "\n",
    "        predicted_id = torch.argmax(logits, dim=-1).item()\n",
    "        predicted_label = list(category_to_id.keys())[predicted_id]\n",
    "        \n",
    "\n",
    "        print(f\"Ground Truth: {inputs['category']}\")\n",
    "        print(f\"Predicted Label: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = 55\n",
    "inputs = dataset[\"test\"][test_id]\n",
    "play_audio(inputs)\n",
    "predict_and_audio(inputs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
